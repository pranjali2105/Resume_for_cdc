{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-01T05:45:10.986984Z",
     "start_time": "2024-09-01T05:44:48.764402Z"
    }
   },
   "source": [
    "import ollama\n",
    "import rir_api\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def process_with_vlm(segmented_image_path):\n",
    "    load_dotenv()\n",
    "    openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "    system_text = \"You are an advanced visual analysis assistant. Your role is to analyze images, identify key elements, and describe the scene in detail.\"\n",
    "    \n",
    "    api = rir_api.RIR_API(openai_api_key)\n",
    "    image_url = f\"file://{segmented_image_path}\"\n",
    "    query_text = \"What is in this image?\"\n",
    "    \n",
    "    response = api.query_with_image(image_url, query_text)\n",
    "    additional_context = response['context']\n",
    "    \n",
    "    text = (\n",
    "        f\"Based on the image and additional context: {additional_context}, analyze the image in detail. \"\n",
    "        \"Describe all visible objects, their colors, sizes, shapes, positions, and any unique features. \"\n",
    "        \"Explain the relationships between the objects, their potential functions, and the context of the scene. \"\n",
    "        \"If there are any patterns, textures, or materials, describe them as well. \"\n",
    "        \"Additionally, infer the possible purpose or scenario depicted in the image, considering cultural, environmental, or functional aspects. \"\n",
    "        \"Provide any relevant background information or assumptions that could be drawn based on the visual elements.\"\n",
    "    )\n",
    "\n",
    "    prompt = f\"<s>[INST]<<SYS>>\\n{system_text}<<\\SYS>>\\n{text}[/INST]\"\n",
    "\n",
    "    vlm_response = ollama.chat(\n",
    "        model='llava',\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': prompt,\n",
    "                'image': segmented_image_path\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return vlm_response['message']['content']\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The image shows a person standing indoors, looking out of a window. The individual is wearing a white shirt and dark pants. They are holding a camera, suggesting they may be preparing to take a photograph.\n",
      "\n",
      "The room has a white wall on the left side, and there appears to be a small object with red and white colors near the person's feet. The flooring is not clearly visible due to the angle of the photo. On the right side, there is another object that looks like a light-colored box or package.\n",
      "\n",
      "The window the person is looking through has no visible curtains or blinds. Outside the window, there are trees and what appears to be a clear sky, indicating it might be daytime with good weather conditions. The presence of natural light suggests that the room is well lit.\n",
      "\n",
      "Based on the available information, it can be inferred that the person could be capturing a photograph of the outdoor scenery or an interesting subject outside the window. The red and white object near the person's feet may be something they are interested in photographing or simply an item in the room. The light-colored box or package might be a decoration, a piece of furniture, or even a product that the person is documenting for some reason.\n",
      "\n",
      "Without additional context, it is difficult to determine the exact purpose or scenario depicted in the image. However, it is likely that the person is capturing an image of their immediate surroundings or something they find noteworthy or appealing. The presence of natural light and the outdoor scenery suggest a calm and serene environment, which might be conducive to creative endeavors like photography. \n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4bb7b9dfca442b52"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
